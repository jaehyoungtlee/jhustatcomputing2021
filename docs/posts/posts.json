[
  {
    "path": "posts/2021-09-02-building-websites/",
    "title": "Building websites in RMarkdown",
    "description": "Add a short description here.",
    "author": [
      {
        "name": "Stephanie Hicks",
        "url": "https://stephaniehicks.com/"
      }
    ],
    "date": "2021-09-02",
    "categories": [
      "module 1",
      "week 2",
      "R Markdown",
      "websites",
      "programming"
    ],
    "contents": "\n\nContents\nPre-lecture materials\nRead ahead\nAcknowledgements\n\nLearning objectives\nSection 1\nSubsection 1\nSubsection 2\nSubsection 3\n\nSection 2\nPost-lecture materials\nFinal Questions\nAdditional Resources\n\n\n\nPre-lecture materials\nRead ahead\n\nBefore class, you can prepare by reading the following materials:\n\n\nAcknowledgements\nMaterial for this lecture was borrowed and adopted from\n\n\n\nLearning objectives\n\nAt the end of this lesson you will:\n\n\n\n\nSection 1\nSubsection 1\nSubsection 2\n\nQuestions:\n\n\n\n\nSubsection 3\nSection 2\nPost-lecture materials\nFinal Questions\nHere are some post-lecture questions to help you think about the material discussed.\n\nQuestions:\n\n\n\n\nAdditional Resources\n\n\n\n\n\n\n\n\n",
    "preview": {},
    "last_modified": "2021-07-20T23:12:25-04:00",
    "input_file": "building-websites.knit.md"
  },
  {
    "path": "posts/2021-09-02-literate-programming/",
    "title": "Literate Statistical Programming",
    "description": "Add a short description here.",
    "author": [
      {
        "name": "Stephanie Hicks",
        "url": "https://stephaniehicks.com/"
      }
    ],
    "date": "2021-09-02",
    "categories": [
      "module 1",
      "week 2",
      "R Markdown",
      "programming"
    ],
    "contents": "\n\nContents\nPre-lecture materials\nRead ahead\nAcknowledgements\n\nLearning objectives\nIntroduction\nWeaving and Tangling\nSweave\nknitr\nSummary\n\nSection 2\nPost-lecture materials\nFinal Questions\nAdditional Resources\n\n\n\nPre-lecture materials\nRead ahead\n\nBefore class, you can prepare by reading the following materials:\n\n\nAcknowledgements\nMaterial for this lecture was borrowed and adopted from\n\n\n\nLearning objectives\n\nAt the end of this lesson you will:\n\n\n\n\nIntroduction\nOne basic idea to make writing reproducible reports easier is what’s known as literate statistical programming (or sometimes called literate statistical practice). This comes from the idea of literate programming in the area of writing computer programs.\nThe idea is to think of a report or a publication as a stream of text and code. The text is readable by people and the code is readable by computers. The analysis is described in a series of text and code chunks. Each kind of code chunk will do something like load some data or compute some results. Each text chunk will relay something in a human readable language. There might also be presentation code that formats tables and figures and there’s article text that explains what’s going on around all this code. This stream of text and code is a literate statistical program or a literate statistical analysis.\nWeaving and Tangling\nLiterate programs by themselves are a bit difficult to work with, but they can be processed in two important ways. Literate programs can be weaved to produce human readable documents like PDFs or HTML web pages, and they can tangled to produce machine-readable “documents”, or in other words, machine readable code. The basic idea behind literate programming in order to generate the different kinds of output you might need, you only need a single source document—you can weave and tangle to get the rist. In order to use a system like this you need a documentational language, that’s human readable, and you need a programming language that’s machine readable (or can be compiled/interpreted into something that’s machine readable).\nSweave\nOne of the original literate programming systems in R that was designed to do this was called Sweave. Sweave uses a documentation program called LaTeX and a programming language, which obviously is R. It was originally developed by Fritz Leisch, who is a core member of R, and the code base is still maintained by R Core. The Sweave system comes with a any installation of R.\nThere are many limitations to the original Sweave system. One of the limitations is that it is focused primarily on LaTeX, which is not a documentation language that many people are familiar with. Therefore, it can be difficult to learn this type of markup language if you’re not already in a field that uses it regularly. Sweave also lacks a lot of features that people find useful like caching, and multiple plots per page and mixing programming languages.\nknitr\nOne of the alternative that has come up in recent times is something called knitr. The knitr package for R takes a lot of these ideas of literate programming and updates and improves upon them. knitr still uses R as its programming language, but it allows you to mix other programming languages in. You can also use a variety of documentation languages now, such as LaTeX, markdown and HTML. knitr was developed by Yihui Xie while he was a graduate student at Iowa State and it has become a very popular package for writing literate statistical programs.\nDEMO: Creating and Knitting Your First R Markdown Document\n\n\nWhen creating your first R Markdown document, in RStudio you can\nGo to File > New File > R Markdown…\nFeel free to edit the Title\nMake sure to select “Default Output Format” to be HTML\nClick “OK”. RStudio creates the R Markdown document and places some boilerplate text in there just so you can see how things are setup.\nClick the “Knit” button (or goto File > Knit Document) to make sure you can create the HTML output\nSummary\nLiterate statistical programming tools can make it easier to write up reproducible documents containing data analyses.\nSweave was one of the first literate statistical programming tools, which weaved together a statistical language (R) with a markup language (LaTeX).\nknitr is a package that builds on the work of Sweave and provides much more powerful functionality, including the ability to write in Markdown and create a variety of output formats.\n\nQuestions:\n\n\n\n\nSection 2\nPost-lecture materials\nFinal Questions\nHere are some post-lecture questions to help you think about the material discussed.\n\nQuestions:\n\n\n\n\nAdditional Resources\n\n\n\n\n\n\n\n\n",
    "preview": {},
    "last_modified": "2021-07-20T23:12:36-04:00",
    "input_file": "literate-programming.knit.md"
  },
  {
    "path": "posts/2021-09-02-reference-management/",
    "title": "Reference management",
    "description": "Add a short description here.",
    "author": [
      {
        "name": "Stephanie Hicks",
        "url": "https://stephaniehicks.com/"
      }
    ],
    "date": "2021-09-02",
    "categories": [
      "module 1",
      "week 2",
      "R Markdown",
      "programming"
    ],
    "contents": "\n\nContents\nPre-lecture materials\nRead ahead\nAcknowledgements\n\nLearning objectives\nSection 1\nSubsection 1\nSubsection 2\nSubsection 3\n\nSection 2\nPost-lecture materials\nFinal Questions\nAdditional Resources\n\n\n\nPre-lecture materials\nRead ahead\n\nBefore class, you can prepare by reading the following materials:\n\n\nAcknowledgements\nMaterial for this lecture was borrowed and adopted from\n\n\n\nLearning objectives\n\nAt the end of this lesson you will:\n\n\n\n\nSection 1\nSubsection 1\nSubsection 2\n\nQuestions:\n\n\n\n\nSubsection 3\nSection 2\nPost-lecture materials\nFinal Questions\nHere are some post-lecture questions to help you think about the material discussed.\n\nQuestions:\n\n\n\n\nAdditional Resources\n\n\n\n\n\n\n\n\n",
    "preview": {},
    "last_modified": "2021-07-20T23:12:31-04:00",
    "input_file": "reference-management.knit.md"
  },
  {
    "path": "posts/2021-09-02-reproducible-research/",
    "title": "Reproducible Research and R Markdown",
    "description": "Introduction to reproducible research covering some basic concepts and ideas that are related to reproducible reporting",
    "author": [
      {
        "name": "Stephanie Hicks",
        "url": "https://stephaniehicks.com/"
      }
    ],
    "date": "2021-09-02",
    "categories": [
      "module 1",
      "week 2",
      "R",
      "reproducibility"
    ],
    "contents": "\n\nContents\nPre-lecture materials\nRead ahead\nAcknowledgements\n\nLearning objectives\nIntroduction\nWhat is Wrong with Replication?\nReproducibility to the Rescue\nFrom “X” to “Computational X”\nAir Pollution and Health: A Perfect Storm\nSummary\n\n\nSection 2\nPost-lecture materials\nFinal Questions\nAdditional Resources\n\n\n\nPre-lecture materials\nRead ahead\n\nBefore class, you can prepare by reading the following materials:\n\n\nAcknowledgements\nMaterial for this lecture was borrowed and adopted from\n\n\n\nLearning objectives\n\nAt the end of this lesson you will:\n\n\n\n\nIntroduction\nThis lecture will be about reproducible reporting, and I want to take the opportunity to cover some basic concepts and ideas that are related to reproducible reporting, just in case you have not heard about it or don’t know what it is.\nBefore we get to reproducibility, we need to cover a little background with respect to how science works (even if you are not a scientist, this is important). The basic idea is that in science, replication is the most important element of verifying and validating findings. So if you claim that X causes Y, or that Vitamin C improves disease, or that something causes a problem, what happens is that other scientists that are independent of you will try to investigate that same question and see if they come up with a similar result. If lots of different people come up with the same result and replicate the original finding, then we tend to think that the original finding was probably true and that this is a real relationship or real finding.\nThe ultimate standard in strengthening scientific evidence is replication. The goal is to have independent people to do independent things with different data, different methods, and different laboratories and see if you get the same result. There’s a sense that if a relationship in nature is truly there, then it should be robust to having different people discover it in different ways. Replication is particularly important in areas where findings can have big policy impacts or can influence regulatory types of decisions.\nWhat is Wrong with Replication?\nWhat is wrong with replication? There is really nothing wrong with it. This is what science has been doing for a long time, through hundreds of years. And there’s nothing wrong with it today. But the problem is that it’s becoming more and more challenging to do replication or to replicate other studies. Part of the reason is because studies are getting bigger and bigger.\nIn order to do big studies you need a lot of money and so, well, there is a lot of money involved! If you want to do ten versions of the same study, you need ten times as much money and there is not as much money around as there used to be. Sometimes it is difficult to replicate a study because if the original study took 20 years to do, it’s difficult to wait around another 20 years for replication. Some studies are just plain unique, such as studying the impact of a massive earthquake in a very specific location and time. If you are looking at a unique situation in time or a unique population, you can’t readily replicate that situation.\nThere are a lot of good reasons why you cannot replicate a study. If you cannot replicate a study, is the alternative just to do nothing, just let that study stand by itself? The idea behind a reproducible reporting is to create a kind of minimum standard or a middle ground where we won’t be replicating a study, but maybe we can do something in between. The basic problem is that you have the gold standard, which is replication, and then you have the worst standard which is doing nothing. What can we do that’s in between the gold standard and diong nothing? That is where reproducibility comes in. That’s how we can kind of bridge the gap between replication and nothing.\nIn non-research settings, often full replication is not even the point. Often the goal is to preserve something to the point where anybody in an organization can repeat what you did (for example, after you leave the organization). In this case, reproducibility is key to maintaining the history of a project and making sure that every step along the way is clear.\nReproducibility to the Rescue\nWhy do we need this kind of middle ground? I haven’t clearly defined reproducibility yet, but the basic idea is that you need to make the data available for the original study and the computational methods available so that other people can look at your data and run the kind of analysis that you’ve run, and come to the same findings that you found.\nWhat reproducible reporting is about is a validation of the data analysis. Because you’re not collecting independent data using independent methods, it’s a little bit more difficult to validate the scientific question itself. But if you can take someone’s data and reproduce their findings, then you can, in some sense, validate the data analysis. This involves having the data and the code because more likely than not, the analysis will have been done on the computer using some sort of programming language, like R. So you can take their code and their data and reproduce the findings that they come up with. Then you can at least have confidence that the analysis was done appropriately and that the correct methods were used.\nRecently, there’s been a lot of discussion of reproducibility in the media and in the scientific literature. The journal Science had a special issue on reproducibility and data replication. Other journals of updated policies on publication to encourage reproducibility. In 2012, a feature on the TV show 60 minutes looked at a major incident at Duke University where many results involving a promising cancer test were found to be not reproducible. This led to a number of studies and clinical trials having to be stopped, followed by an investigation which is still ongoing.\nFinally, the Institute of Medicine, in response to a lot of recent events involving reproducibility of scientific studies, issued a report saying that best practices should be done to promote and encourage reproducibility, particularly in what’s called ’omics based research, such as genomics, proteomics, other similar areas involving high-throughput biological measurements. This was a very important report. Of the many recommendations that the IOM made, the key ones were that\nData and metadata need to be made available;\nComputer code should be fully specified, so that people can examine it to see what was done;\nAll the steps of the computational analysis, including any preprocessing of data, should be fully described so that people can study it and reproduce it.\nFrom “X” to “Computational X”\nWhat is driving this need for a “reproducibility middle ground” between replication and doing nothing? For starters, there are a lot of new technologies on the scene and in many different fields of study including, biology, chemistry and environmental science. These technologies allow us to collect data at a much higher throughput so we end up with these very complex and very high dimensional data sets. These datasets can be collected almost instantaneously compared to even just ten years ago—the technology has allowed us to create huge data sets at essentially the touch of a button. Furthermore, we the computing power to take existing (already huge) databases and merge them into even bigger and bigger databases. Finally, the massive increase in computing power has allowed us to implement more sophisticated and complex analysis routines.\nThe analyses themselves, the models that we fit and the algorithms that we run, are much much more complicated than they used to be. Having a basic understanding of these algorithms is difficult, even for a sophisticated person, and it’s almost impossible to describe these algorithms with words alone. Understanding what someone did in a data analysis now requires looking at code and scrutinizing the computer programs that people used.\nThe bottom line with all these different trends is that for every field “X”, there is now “Computational X”. There’s computational biology, computational astronomy—whatever it is you want, there is a computational version of it.\nAir Pollution and Health: A Perfect Storm\nOne example of an area were reproducibility is important comes from research that I’ve conducted in the area of air pollution and health. Air pollution and health is a big field and it involves a confluence of features that emphasize the need for reproducibility.\nThe first feature is that we’re estimating very small, but very important, public health effects in the presence of a numerous much stronger signals. You can think about air pollution as something that’s perhaps harmful, but even if it were harmful there are likely many other things that are going to be more harmful that you have to worry about. Pollution is going to be at the very top of the list of things that are going to harm you. In other words, there’s an inherently weak signal there.\nSecond, the results of a lot of air pollution research inform substantial policy decisions. Many federal air pollution regulations in the United States are based on scientific research in this area and these regulations can affect a lot of stakeholders in government and industry.\nFinally, we use a lot of complex statistical methods to do these studies and these statistical methods are subsequently subjected to intense scrutiny. The combination of an inherently weak signal, substantial policy impacts, and complex statistical methods almost require that the research that we do be reproducible.\nSummary\nReplication, whereby scientific questions are examined and verified independently by different scientists, is the gold standard for scientific validity.\nReplication can be difficult and often there are no resources to independently replicate a study.\nReproducibility, whereby data and code are re-analyzed by independent scientists to obtain the same results of the original investigator, is a reasonable minimum standard when replication is not possible.\n\nQuestions:\n\n\n\n\nSection 2\nPost-lecture materials\nFinal Questions\nHere are some post-lecture questions to help you think about the material discussed.\n\nQuestions:\n\n\n\n\nAdditional Resources\n\n\n\n\n\n\n\n\n",
    "preview": {},
    "last_modified": "2021-07-20T23:09:49-04:00",
    "input_file": "reproducible-research.knit.md"
  },
  {
    "path": "posts/2021-08-31-introduction-to-gitgithub/",
    "title": "Introduction to git/GitHub",
    "description": "Version control is a game changer; or how I learned to love git/GitHub",
    "author": [
      {
        "name": "Stephanie Hicks",
        "url": "https://stephaniehicks.com/"
      }
    ],
    "date": "2021-08-31",
    "categories": [
      "module 1",
      "week 1",
      "programming",
      "version control",
      "git",
      "GitHub"
    ],
    "contents": "\n\nContents\nPre-lecture materials\nRead ahead\nAcknowledgements\n\nLearning objectives\nIntroduction to git/GitHub\ngit\nGitHub\nWhy use git/GitHub?\nWhat to (not) do\nHow to use Git/GitHub\n\nGetting Started\nUsing git/GitHub in our course\nPost-lecture materials\nFinal Questions\nAdditional Resources\n\n\n\nPre-lecture materials\nRead ahead\n\nBefore class, you can prepare by reading the following materials:\nHappy Git with R from Jenny Bryan\nChapter on git and GitHub in dsbook from Rafael Irizarry\n\nAcknowledgements\nMaterial for this lecture was borrowed and adopted from\nhttps://andreashandel.github.io/MADAcourse/\nLearning objectives\n\nAt the end of this lesson you will:\nKnow what Git and GitHub are.\nKnow why one might want to use them.\nHave created and set up a GitHub account.\n\nIntroduction to git/GitHub\nThis document gives a brief explanation of GitHub and how we will use it for this course.\ngit\nGit is what is called a version control system for file management. The main idea is that as you (and your collaborators) work on a project, the software tracks, and records any changes made by anyone.\nSimilar to the “track changes” features in Microsoft Word, but more rigorous, powerful, and scaled up to multiple files\nGreat for solo or collaborative work\nGitHub\nGitHub is a hosting service on internet for git-aware folders and projects\nSimilar to the DropBox or Google, but more structured, powerful, and programmatic\nGreat for solo or collaborative work!\nTechnically GitHub is distinct from Git. However, GitHub is in some sense the interface and Git the underlying engine (a bit like RStudio and R).\nSince we will only be using Git through GitHub, I tend to not distinguish between the two. In the following, I refer to all of it as just GitHub. Note that other interfaces to Git exist, e.g., Bitbucket, but GitHub is the most widely used one.\nWhy use git/GitHub?\nYou want to use GitHub to avoid this:\n\n\n\nFigure 1: How not to use GitHub [image from PhD Comics]\n\n\n\n[Source: PhD Comics]\nGitHub gives you a clean way to track your projects. It is also very well suited to collaborative work. Historically, version control was used for software development. However, it has become broader and is now used for many types of projects, including data science projects.\nTo learn a bit more about Git/GitHub and why you might want to use it, read this article by Jenny Bryan.\nNote her explanation of what’s special with the README.md file on GitHub.\nWhat to (not) do\nGitHub is ideal if you have a project with a fair number of files, most of those files are text files (such as code, LaTeX, (R)markdown, etc.) and different people work on different parts of the project.\nGitHub is less useful if you have a lot of non-text files (e.g. Word or Powerpoint) and different team members might want to edit the same document at the same time. In that instance, a solution like Google Docs, Word+Dropbox, Word+Onedrive, etc. might be better.\nHow to use Git/GitHub\nGit and GitHub is fundamentally based on commands you type into the command line. Lots of online resources show you how to use the command line. This is the most powerful, and the way I almost always interact with git/GitHub. However, many folks find this the most confusing way to use git/GitHub. Alternatively, there are graphical interfaces.\nGitHub itself provides a grapical interface with basic functionality.\nRStudio also has Git/GitHub integration. Of course this only works for R project GitHub integration.\nThere are also third party GitHub clients with many advanced features, most of which you won’t need initially, but might eventually.\nNote: As student, you can (and should) upgrade to the Pro version of GitHub for free (i.e. access to unlimited private repositories is one benefit), see the GitHub student developer pack on how to do this.\nGetting Started\nOne of my favorite resources for getting started with git/GitHub is the Happy Git with R from Jenny Bryan:\nhttps://happygitwithr.com\n\n\n\nFigure 2: A screenshot of the Happy Git with R online book from Jenny Bryan .\n\n\n\nIt truly is one of the best resources out there for getting started with git/GitHub, especially with the integration to RStudio. Therefore, at this point, I will encourage all of you to go read through the online book.\nSome of you may only need to skim it, others will need to spend some time reading through it. Either way, I will bet that you won’t regret the time investment.\nUsing git/GitHub in our course\nIn this course, you will use git/GitHub in the following ways:\nProject 0 (optional) - You will create a website introducing yourself to folks in the course and deploy it on GitHub.\nProject 1 and Project 2 - You will be asked to practice using git locally (on your compute environment) to track your changes over time and, if you wish (but highly suggested), you can practice pushing your project solutions to a private GitHub repository on your GitHub account.\nProject 3 - You will be asked to work collaboratively on a project (i.e. writing code as a group) and you will use the skills you have been practicing in the earlier projects (i.e. git add, git commit, git push, git pull, etc) to work together as a team in a single GitHub repository.\nPost-lecture materials\nFinal Questions\nHere are some post-lecture questions to help you think about the material discussed.\n\nQuestions:\nWhat is version control?\nWhat is the difference between git and GitHub?\nWhat are other version controls tools that are available?\n\nAdditional Resources\n\ngit and GitHub in the `dsbook by Rafael Irizarry.\n\n\n\n\n",
    "preview": "posts/2021-08-31-introduction-to-gitgithub/../../images/phdversioncontrol.gif",
    "last_modified": "2021-07-20T15:01:26-04:00",
    "input_file": {}
  },
  {
    "path": "posts/2021-08-31-introduction-to-r-and-rstudio/",
    "title": "Introduction to R and RStudio",
    "description": "Let's dig into the R programming language and the RStudio integrated developer environment",
    "author": [
      {
        "name": "Stephanie Hicks",
        "url": "https://stephaniehicks.com/"
      }
    ],
    "date": "2021-08-31",
    "categories": [
      "module 1",
      "week 1",
      "R",
      "programming",
      "RStudio"
    ],
    "contents": "\n\nContents\nPre-lecture materials\nRead ahead\nAcknowledgements\n\nLearning objectives\nOverview and history of R\ntl;dr (R in a nutshell)\nBasic Features of R\nFree Software\nDesign of the R System\nLimitations of R\n\nUsing R and RStudio\nInstalling R and RStudio\nRStudio default options\nInstalling and loading R packages\nGetting started in RStudio\n\nPost-lecture materials\nFinal Questions\nAdditional Resources\n\n\n\nThere are only two kinds of languages: the ones people complain about and the ones nobody uses. —Bjarne Stroustrup\n\nPre-lecture materials\nRead ahead\n\nBefore class, you can prepare by reading the following materials:\nAn overview and history of R from Roger Peng\nInstalling R and RStudio from Rafael Irizarry\nGetting Started in R and RStudio from Rafael Irizarry\n\nAcknowledgements\nMaterial for this lecture was borrowed and adopted from\nhttps://rdpeng.github.io/Biostat776/lecture-introduction-and-overview.html\nhttps://rafalab.github.io/dsbook\nhttps://rmd4sci.njtierney.com\nhttps://andreashandel.github.io/MADAcourse\nLearning objectives\n\nAt the end of this lesson you will:\nLearn about (some of) the history of R.\nIdentify some of the strengths and weaknesses of R.\nInstall R and Rstudio on your computer.\nKnow how to install and load R packages.\n\nOverview and history of R\nBelow is a very quick introduction to R, to get you set up and running. We’ll go deeper into R and coding later.\ntl;dr (R in a nutshell)\nLike every programming language, R has its advantages and disadvantages. If you search the internet, you will quickly discover lots of folks with opinions about R. Some of the features that are useful to know are:\nR is open-source, freely accessible, and cross-platform (multiple OS).\nR is a “high-level” programming language, relatively easy to learn.\nWhile “Low-level” programming languages (e.g. Fortran, C, etc) often have more efficient code, they can also be harder to learn because it is designed to be close to a machine language.\nIn contrast, high-level languages deal more with variables, objects, functions, loops, and other abstract CS concepts with a focus on usability over optimal program efficiency.\n\nR is great for statistics, data analysis, websites, web apps, data visualizations, and so much more!\nR integrates easily with document preparation systems like \\(\\LaTeX\\), but R files can also be used to create .docx, .pdf, .html, .ppt files with integrated R code output and graphics.\nThe R Community is very dynamic, helpful and welcoming.\nCheck out the #rstats on Twitter, TidyTuesday podcast and community activity in the R4DS Online Learning Community, and r/rstats subreddit.\nIf you are looking for more local resources, check out R-Ladies Baltimore.\n\nThrough R packages, it is easy to get lots of state-of-the-art algorithms.\nDocumentation and help files for R are generally good.\nWhile we use R in this course, it is not the only option to analyze data. Maybe the most similar to R, and widely used, is Python, which is also free. There is also commercial software that can be used to analyze data (e.g., Matlab, Mathematica, Tableau, SAS, SPSS). Other more general programming languages are suitable for certain types of analyses as well (e.g., C, Fortran, Perl, Java, Julia).\nDepending on your future needs or jobs, you might have to learn one or several of those additional languages. The good news is that even though those languages are all different, they all share general ways of thinking and structuring code. So once you understand a specific concept (e.g., variables, loops, branching statements or functions), it applies to all those languages. Thus, learning a new programming language is much easier once you already know one. And R is a good one to get started with.\nWith the skills gained in this course, hopefully you will find R a fun and useful programming langauge for your future projects.\n\n\n\nFigure 1: Artwork by Allison Horst on learning R\n\n\n\n[Source: Artwork by Allison Horst]\nBasic Features of R\nToday R runs on almost any standard computing platform and operating system. Its open source nature means that anyone is free to adapt the software to whatever platform they choose. Indeed, R has been reported to be running on modern tablets, phones, PDAs, and game consoles.\nOne nice feature that R shares with many popular open source projects is frequent releases. These days there is a major annual release, typically in October, where major new features are incorporated and released to the public. Throughout the year, smaller-scale bugfix releases will be made as needed. The frequent releases and regular release cycle indicates active development of the software and ensures that bugs will be addressed in a timely manner. Of course, while the core developers control the primary source tree for R, many people around the world make contributions in the form of new feature, bug fixes, or both.\nAnother key advantage that R has over many other statistical packages (even today) is its sophisticated graphics capabilities. R’s ability to create “publication quality” graphics has existed since the very beginning and has generally been better than competing packages. Today, with many more visualization packages available than before, that trend continues. R’s base graphics system allows for very fine control over essentially every aspect of a plot or graph. Other newer graphics systems, like lattice and ggplot2 allow for complex and sophisticated visualizations of high-dimensional data.\nR has maintained the original S philosophy (see box below), which is that it provides a language that is both useful for interactive work, but contains a powerful programming language for developing new tools. This allows the user, who takes existing tools and applies them to data, to slowly but surely become a developer who is creating new tools.\n\nFor a great discussion on an overview and history of R and the S programming language, read through this chapter from Roger D. Peng.\n\nFinally, one of the joys of using R has nothing to do with the language itself, but rather with the active and vibrant user community. In many ways, a language is successful inasmuch as it creates a platform with which many people can create new things. R is that platform and thousands of people around the world have come together to make contributions to R, to develop packages, and help each other use R for all kinds of applications. The R-help and R-devel mailing lists have been highly active for over a decade now and there is considerable activity on web sites like Stack Overflow, Twitter #rstats and Reddit.\nFree Software\nA major advantage that R has over many other statistical packages and is that it’s free in the sense of free software (it’s also free in the sense of free beer). The copyright for the primary source code for R is held by the R Foundation and is published under the GNU General Public License version 2.0.\nAccording to the Free Software Foundation, with free software, you are granted the following four freedoms\nThe freedom to run the program, for any purpose (freedom 0).\nThe freedom to study how the program works, and adapt it to your needs (freedom 1). Access to the source code is a precondition for this.\nThe freedom to redistribute copies so you can help your neighbor (freedom 2).\nThe freedom to improve the program, and release your improvements to the public, so that the whole community benefits (freedom 3). Access to the source code is a precondition for this.\n\nYou can visit the Free Software Foundation’s web site to learn a lot more about free software. The Free Software Foundation was founded by Richard Stallman in 1985 and Stallman’s personal web site is an interesting read if you happen to have some spare time.\n\nDesign of the R System\nThe primary R system is available from the Comprehensive R Archive Network, also known as CRAN. CRAN also hosts many add-on packages that can be used to extend the functionality of R.\nThe R system is divided into 2 conceptual parts:\nThe “base” R system that you download from CRAN:\nLinux\nWindows\nMac\nEverything else.\nR functionality is divided into a number of packages.\nThe “base” R system contains, among other things, the base package which is required to run R and contains the most fundamental functions.\nThe other packages contained in the “base” system include utils, stats, datasets, graphics, grDevices, grid, methods, tools, parallel, compiler, splines, tcltk, stats4.\nThere are also “Recommended” packages: boot, class, cluster, codetools, foreign, KernSmooth, lattice, mgcv, nlme, rpart, survival, MASS, spatial, nnet, Matrix.\nWhen you download a fresh installation of R from CRAN, you get all of the above, which represents a substantial amount of functionality. However, there are many other packages available:\nThere are over 10,000 packages on CRAN that have been developed by users and programmers around the world.\nThere are also many packages associated with the Bioconductor project.\nPeople often make packages available on their personal websites; there is no reliable way to keep track of how many packages are available in this fashion.\n\nQuestions:\nHow many R packages are on CRAN today?\nHow many R packages are on Bioconductor today?\nHow many R packages are on GitHub today?\n\nLimitations of R\nNo programming language or statistical analysis system is perfect. R certainly has a number of drawbacks. For starters, R is essentially based on almost 50 year old technology, going back to the original S system developed at Bell Labs. There was originally little built in support for dynamic or 3-D graphics (but things have improved greatly since the “old days”).\nAnother commonly cited limitation of R is that objects must generally be stored in physical memory (though this is increasingly not true anymore). This is in part due to the scoping rules of the language, but R generally is more of a memory hog than other statistical packages. However, there have been a number of advancements to deal with this, both in the R core and also in a number of packages developed by contributors. Also, computing power and capacity has continued to grow over time and amount of physical memory that can be installed on even a consumer-level laptop is substantial. While we will likely never have enough physical memory on a computer to handle the increasingly large datasets that are being generated, the situation has gotten quite a bit easier over time.\nAt a higher level one “limitation” of R is that its functionality is based on consumer demand and (voluntary) user contributions. If no one feels like implementing your favorite method, then it’s your job to implement it (or you need to pay someone to do it). The capabilities of the R system generally reflect the interests of the R user community. As the community has ballooned in size over the past 10 years, the capabilities have similarly increased. When I first started using R, there was very little in the way of functionality for the physical sciences (physics, astronomy, etc.). However, now some of those communities have adopted R and we are seeing more code being written for those kinds of applications.\nUsing R and RStudio\n\nIf R is the engine and bare bones of your car, then RStudio is like the rest of the car. The engine is super critical part of your car. But in order to make things properly functional, you need to have a steering wheel, comfy seats, a radio, rear and side view mirrors, storage, and seatbelts. — Nicholas Tierney\n\n[Source]\nThe RStudio layout has the following features:\nOn the upper left, something called a Rmarkdown script\nOn the lower left, the R console\nOn the lower right, the view for files, plots, packages, help, and viewer.\nOn the upper right, the environment / history pane\n\n\n\nFigure 2: A screenshot of the RStudio integrated developer environment (IDE) – aka the working environment.\n\n\n\nThe R console is the bit where you can run your code. This is where the R code in your Rmarkdown document gets sent to run (we’ll learn about these files later).\nThe file/plot/pkg viewer is a handy browser for your current files, like Finder, or File Explorer, plots are where your plots appear, you can view packages, see the help files. And the environment / history pane contains the list of things you have created, and the past commands that you have run.\nInstalling R and RStudio\nIf you have not already, install R first. If you already have R installed, make sure it is a fairly recent version, version 4.0 or newer. If yours is older, I suggest you update (install a new R version).\nOnce you have R installed, install the free version of RStudio Desktop. Again, make sure it’s a recent version, it should be of the 1.4.X series.\n\nInstalling R and RStudio should be fairly straightforward. However, a great set of detailed instructions is in Rafael Irizarry’s dsbook\nhttps://rafalab.github.io/dsbook/installing-r-rstudio.html\n\nIf things don’t work, ask for help in the courseplus discussion board.\nI personally only have experience with Mac, but everything should work on all the standard operating systems (Windows, Mac, and even Linux).\nRStudio default options\nTo first get set up, I highly recommend changing the following setting\nTools > Global Options (or Cmd + , on macOS)\nUnder the General tab:\nFor workspace\nUncheck restore .RData into workspace at startup\nSave workspace to .RData on exit : “Never”\n\nFor History\nUncheck \"Always save history (even when not saving .RData)\nUncheck “Remove duplicate entries in history”\n\nThis means that you won’t save the objects and other things that you create in your R session and reload them. This is important for two reasons\nReproducibility: you don’t want to have objects from last week cluttering your session\nPrivacy: you don’t want to save private data or other things to your session. You only want to read these in.\nYour “history” is the commands that you have entered into R.\nAdditionally, not saving your history means that you won’t be relying on things that you typed in the last session, which is a good habit to get into!\nInstalling and loading R packages\nAs we discussed, most of the functionality and features in R come in the form of add-on packages. There are tens of thousands of packages available, some big, some small, some well documented, some not. We will be using many different packages in this course. Of course, you are free to install and use any package you come across for any of the assignments.\nThe “official” place for packages is the CRAN website. If you are interested in packages on a specific topic, the CRAN task views provide curated descriptions of packages sorted by topic.\nTo install an R package from CRAN, one can simply call the install.packages() function and pass the name of the package as an argument. For example, to install the ggplot2 package from CRAN: open RStudio,go to the R prompt (the > symbol) in the lower-left corner and type\n\n\ninstall.packages(\"ggplot2\")\n\n\n\nand the appropriate version of the package will be installed.\nOften, a package needs other packages to work (called dependencies), and they are installed automatically. It usually does not matter if you use a single or double quotation mark around the name of the package.\n\nQuestions:\nAs you installed the ggplot2 package, what other packages were installed?\nWhat happens if you tried to install GGplot2?\n\nIt could be that you already have all packages required by ggplot2 installed. In that case, you will not see any other packages installed. To see which of the packages above ggplot2 needs (and thus installs if it is not present), type into the R console:\n\n\ntools::package_dependencies(\"ggplot2\")\n\n\n\nIn RStudio, you can also install (and update/remove) packages by clicking on the ‘Packages’ tab in the bottom right window.\nIt is very common these days for packages to be developed on GitHub. It is possible to install packages from GitHub directly. Those usually contain the latest version of the package, with features that might not be available yet on the CRAN website. Sometimes, in early development stages, a package is only on GitHub until the developer(s) feel it is good enough for CRAN submission. So installing from GitHub gives you the latest. The downside is that packages under development can often be buggy and not working right. To install packages from GitHub, you need to install the remotes package and then use the following function\n\n\nremotes::install_github()\n\n\n\nWe will not do that now, but it is quite likely that at one point later in this course we will.\nYou only need to install a package once, unless you upgrade/re-install R. Once installed, you still need to load the package before you can use it. That has to happen every time you start a new R session. You do that using the library() command. For instance to load the ggplot2 package, type\n\n\nlibrary('ggplot2')\n\n\n\nYou may or may not see a short message on the screen. Some packages show messages when you load them, and others do not.\nThis was a quick overview of R packages. We will use a lot of them, so you will get used to them rather quickly.\nGetting started in RStudio\nWhile one can use R and do pretty much every task, including all the ones we cover in this class, without using RStudio, RStudio is very useful, has lots of features that make your R coding life easier and has become pretty much the default integrated development environment (IDE) for R. Since RStudio has lots of features, it takes time to learn them. A good resource to learn more about RStudio are the R Studio Essentials collection of videos.\n\nFor more information on setting up and getting started with R, RStudio, and R packages, read the Getting Started chapter in the dsbook:\nhttps://rafalab.github.io/dsbook/getting-started.html\nThis chapter gives some tips, shortcuts, and ideas that might be of interest even to those of you who already have R and/or RStudio experience.\n\nPost-lecture materials\nFinal Questions\nHere are some post-lecture questions to help you think about the material discussed.\n\nQuestions:\nIf a software company asks you, as a requirement for using their software, to sign a license that restricts you from using their software to commit illegal activities, is this consistent with the “Four Freedoms” of Free Software?\nWhat is an R package and what is it used for?\nWhat function in R can be used to install packages from CRAN?\nWhat is a limitation of the current R system?\n\nAdditional Resources\n\nR for Data Science by Wickham & Grolemund (2017). Covers most of the basics of using R for data analysis.\nAdvanced R by Wickham (2014). Covers a number of areas including object-oriented, programming, functional programming, profiling and other advanced topics.\nRStudio IDE cheatsheet\n\n\n\n\n",
    "preview": "https://github.com/allisonhorst/stats-illustrations/raw/master/rstats-artwork/r_first_then.png",
    "last_modified": "2021-07-20T22:36:01-04:00",
    "input_file": {}
  },
  {
    "path": "posts/welcome/",
    "title": "Welcome!",
    "description": "Overview course information for students enrolled in JHSPH Biostatistics 140.776 in Fall 2021",
    "author": [
      {
        "name": "Stephanie Hicks",
        "url": "https://stephaniehicks.com/"
      }
    ],
    "date": "2021-08-31",
    "categories": [
      "course-admin",
      "module 1",
      "week 1"
    ],
    "contents": "\nWelcome! I am very excited to have you in our one-term (half a semester) course on Statistical Computing course number (140.776) offered by the Department of Biostatistics at the Johns Hopkins Bloomberg School of Public Health.\nThis course is designed for ScM and PhD students at Johns Hopkins Bloomberg School of Public Health. We are usually pretty flexible about permitting outside students but we want everyone to be aware of the goals and assumptions so no one feels like they are surprised by how the class works.\n\nThe primary goal of the course is to teach you practical programming and computational skills required for the research and application of statistical methods.\n\n\n\n\n",
    "preview": {},
    "last_modified": "2021-06-29T11:17:28-04:00",
    "input_file": {}
  }
]
