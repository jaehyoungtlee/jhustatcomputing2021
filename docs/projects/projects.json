[
  {
    "path": "projects/2021-10-05-project-3/",
    "title": "Project 3",
    "description": "Building a R package, and practicing S3 and regex skills",
    "author": [
      {
        "name": "Stephanie Hicks",
        "url": "https://stephaniehicks.com/"
      }
    ],
    "date": "2021-10-05",
    "categories": [
      "project 3",
      "projects"
    ],
    "contents": "\n\nContents\nBackground\nTo submit your project\nInstall packages\n\nPart 1: Create a R package\nPart 2: Create a S3 class as part of your package\nPart 3: Create a vignette as part of your package\nPart 3A: Demonstrate Exp()\nPart 3B: Demonstrate calculate_CI()\n\n\nBackground\nDue date: Oct 22 at 11:59pm\nThe goal of this homework is to take some of the functions that you wrote in Project 2 and to put them into an R package. This would allow someone else to easily use your functions by simply installing the R package. In addition, they would receive documentation on how to use the functions.\nIn addition to building the R package, you will also build a S3 class for your package, and create a vignette where you demonstrate the functions in your R package with a small example dataset from TidyTuesday.\nTo submit your project\nPlease build your R package either into a .tar.gz file or to a .zip file and upload the file to the dropbox on Courseplus. Please name the package Project3<your last name> and then upload it to the Courseplus dropbox. So for example, the name of my package would be Project3Hicks.\nThe R package must include a vignette in a folder titled vignettes. This document should be a R Markdown. In the vignette, please show all your code (i.e. make sure to set echo = TRUE).\nInstall packages\nBefore attempting this assignment, you should first install the following packages, if they are not already installed:\n\n\ninstall.packages(\"tidyverse\")\ninstall.packages(\"tidytuesdayR\")\ninstall.packages(\"devtools\")\ninstall.packages(\"roxygen2\")\n\n\n\nPart 1: Create a R package\nTake the functions that you wrote for Parts 1A-1C and put them into an R package. Your package will have two exported functions for users to call (see below). You will need to write documentation for each function that you export. Your package should include the functions:\nExp(), which computes the approximation to the exponential function (exported)\nsample_mean(), which calculates the sample mean (not exported)\nsample_sd(), which calculates the sample standard deviation (not exported)\ncalculate_CI(), which calculates the confidence intervals from simulated data (exported)\nNotes:\nRemember that you should only export the functions that you want the user to use.\nFunctions that are not exported do not require any documentation.\nEach exported function should have at least one example of its usage (using the @example directive in the documentation).\nIn the functions in your package, consider using control structures and include checks (e.g. is.na(), is.numeric(), if()) to make sure the input is as you expect it to be. For example, try to break the the function with unexpected values that a user might provide (e.g. providing a negative value to a log transformation). This can help guide you on ways to address the possible ways to break the function.\nYour package should be installable without any warnings or errors.\nPart 2: Create a S3 class as part of your package\nIn this part, you will create a new S3 class called p3_class (Project 3 class) to be used in your Project 3 R package. You will\nCreate a constructor function for the p3_class called make_p3_class().\nCreate a print() method to work with the p3_class to return a message with name of the class and the the number of observations in the S3 object.\nModify the calculate_CI() function to work with the p3_class and still return a lower_bound and upper_bound, similar to Project 2.\nFor example, this is what the output of your code might look like:\n> set.seed(1234)\n> x <- rnorm(100)\n> p3 <- make_p3_class(x)\n> print(p3)         # explicitly using the print() method\n#> a p3_class with 100 observations\n> p3                  # using autoprinting\n#> a p3_class with 100 observations\nCalculate a 90% confidence interval:\n> calculate_CI(p3, conf = 0.90)\n#> lower_bound upper_bound \n#> -0.32353231  0.01000883\nPart 3: Create a vignette as part of your package\nIn this part, you will create a vignette where you demonstrate the functions in your R package. Specifically, you will create a R Markdown and put it in a folder called “vignettes” within your R package. The purpose of a vignette is to demonstrate the functions of your package in a longer tutorial instead of just short examples within the documentation of your functions (i.e. using the @example directive in the documentation).\nHint: You might find the use_vignette() function from the usethis R package helpful.\nPart 3A: Demonstrate Exp()\nIn the vignette, show how your function Exp(x,k) approximates the exp(x) function from base R as \\(k\\) increases.\nFor example, you could make a plot or you could show something like this in your vignette:\n> # Taylor series approximation\n> Exp(5,k=1)\n[1] 6\n> Exp(5,k=5)\n[1] 91.41667\n> Exp(5,k=10)\n[1] 146.3806\n> Exp(5,k=100)\n[1] 148.4132\n> \n> # compared to \n> exp(5)\n[1] 148.4132\nPart 3B: Demonstrate calculate_CI()\nTo demonstrate the calculate_CI() function in the vignette, we will have a bit of Halloween fun. We will use this dataset from TidyTuesday.\nIt is contains data from the TV show called Chopped:\n\n“Chopped is an American reality-based cooking television game show series. It is hosted by Ted Allen. The series pits four chefs against each other as they compete for a chance to win $10,000.”\n\nYou can read more here about the show:\nhttps://github.com/rfordatascience/tidytuesday/blob/master/data/2020/2020-08-25/readme.md\nI have provided the code below for you to avoid re-downloading data:\n\n\nlibrary(here)\nlibrary(tidyverse)\n\n# tests if a directory named \"data\" exists locally\nif(!dir.exists(here(\"data\"))) { dir.create(here(\"data\")) }\n\n# saves data only once (not each time you knit a R Markdown)\nif(!file.exists(here(\"data\",\"chopped.RDS\"))) {\n  url_tsv <- 'https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2020/2020-08-25/chopped.tsv'\n  chopped <- readr::read_tsv(url_tsv)\n  \n  # save the file to RDS objects\n  saveRDS(chopped, file= here(\"data\",\"chopped.RDS\"))\n}\n\n\n\nHere we read in the .RDS dataset:\n\n\nchopped <- readRDS(here(\"data\",\"chopped.RDS\"))\nas_tibble(chopped)\n\n\n# A tibble: 569 × 21\n   season season_episode series_episode episode_rating episode_name   \n    <dbl>          <dbl>          <dbl>          <dbl> <chr>          \n 1      1              1              1            9.2 Octopus, Duck,…\n 2      1              2              2            8.8 Tofu, Blueberr…\n 3      1              3              3            8.9 Avocado, Tahin…\n 4      1              4              4            8.5 Banana, Collar…\n 5      1              5              5            8.8 Yucca, Waterme…\n 6      1              6              6            8.5 Canned Peaches…\n 7      1              7              7            8.8 Quail, Arctic …\n 8      1              8              8            9   Coconut, Calam…\n 9      1              9              9            8.9 Mac & Cheese, …\n10      1             10             10            8.8 String Cheese,…\n# … with 559 more rows, and 16 more variables: episode_notes <chr>,\n#   air_date <chr>, judge1 <chr>, judge2 <chr>, judge3 <chr>,\n#   appetizer <chr>, entree <chr>, dessert <chr>, contestant1 <chr>,\n#   contestant1_info <chr>, contestant2 <chr>,\n#   contestant2_info <chr>, contestant3 <chr>,\n#   contestant3_info <chr>, contestant4 <chr>, contestant4_info <chr>\n\nThis dataset inclues a set of notes (the episode_notes column) that briefly describe what happened in the episode.\n\n\nas_tibble(chopped) %>% \n  select(episode_notes)\n\n\n# A tibble: 569 × 1\n   episode_notes                                                      \n   <chr>                                                              \n 1 This is the first episode with only three official ingredients in …\n 2 This is the first of a few episodes with five official ingredients…\n 3 <NA>                                                               \n 4 In the appetizer round, Chef Chuboda refused to use bananas in his…\n 5 <NA>                                                               \n 6 <NA>                                                               \n 7 In the appetizer Melinda did not get her quail on 1 plate. As a re…\n 8 In the appetizer round, Chef LePape failed to get any food onto hi…\n 9 Chef Lustberg has also competed on the ninth season of Hell's Kitc…\n10 This is the first episode to feature four male chefs.              \n# … with 559 more rows\n\nAs Halloween is coming up at the end of this month, let’s show users of R package, how to create a confidence interval of the episode ratings for the episodes that were Halloween themed vs not. One might guess that Halloween themed episodes are very popular (more so than the not themed episodes – I mean who doesn’t love “blood sausage”, “coffin toast”, “gummy rats”, “deviled eggs”, or “chocolate covered bugs”??).\nOur new package can help with this!\nIn this part, we will perform the following tasks in the vignette to demonstrate to the users the calculate_CI() function:\nRemove rows that contain an NA in either of the two columns episode_notes or episode_rating.\nAdd a column called has_halloween_theme that searches the character strings in episode_notes for the strings “halloween” or “Halloween”. This column should contain either TRUE or FALSE depending on whether the strings were found (TRUE) or not (FALSE).\nMake two side-by-side boxplots along the x-axis (could be faceted or not) of the distribution of ratings in the episode_rating column: one for the episodes with and without the halloween theme. On top of the boxplot, plot the ratings for the two categories (hint: check out the geom_jitter() function in ggplot2).\nUsing the skills we have learned in the tidyverse and using our new S3 class (p3_class), calculate a 90% confidence interval of the ratings for the episodes with and without the Halloween theme.\nIn your vignette, write 1 - 2 sentences describing what you see related to whether Halloween episodes are more highly rated than non Halloween episodes.\nNote: Steps 3 and 4 should be performed in two separate code chunks in the vignette.\n\n\n\n",
    "preview": {},
    "last_modified": "2021-10-04T11:19:06-04:00",
    "input_file": {}
  },
  {
    "path": "projects/2021-09-14-project-2/",
    "title": "Project 2",
    "description": "Exploring temperature and rainfall in Australia",
    "author": [
      {
        "name": "Stephanie Hicks",
        "url": "https://stephaniehicks.com/"
      }
    ],
    "date": "2021-09-14",
    "categories": [
      "project 2",
      "projects"
    ],
    "contents": "\n\nContents\nBackground\nTo submit your project\nInstall packages\n\nPart 1: Fun with functions\nPart 1A: Exponential transformation\nPart 1B: Sample mean and sample standard deviation\nPart 1C: Confidence intervals\nNotes\n\nPart 2: Wrangling data\nData\nTasks\nNotes\n\nPart 3: Data visualization\nPart 3A: Plotting temperature data over time\nPart 3B: Plotting rainfall over time\n\nPart 4: Apply functions and plot\nPart 4A: Tasks\nPart 4B: Tasks\n\n\nBackground\nDue date: Oct 1 at 11:59pm\nThe goal of this assignment is to get used to designing and writing functions along with practicing our tidyverse skills that we learned in our previous module. Writing functions involves thinking about how code should be divided up and what the interface/arguments should be. In addition, you need to think about what the function will return as output.\nTo submit your project\nPlease write up your project using R Markdown and processed with knitr. Compile your document as an HTML file and submit your HTML file to the dropbox on Courseplus. Please show all your code (i.e. make sure to set echo = TRUE) for each of the answers to each part.\nInstall packages\nBefore attempting this assignment, you should first install the following packages, if they are not already installed:\n\n\ninstall.packages(\"tidyverse\")\ninstall.packages(\"tidytuesdayR\")\n\n\n\nPart 1: Fun with functions\nIn this part, we are going to practice creating functions.\nPart 1A: Exponential transformation\nThe exponential of a number can be written as an infinite series expansion of the form \\[\n\\exp(x) = 1 + x + \\frac{x^2}{2!} + \\frac{x^3}{3!} + \\cdots\n\\] Of course, we cannot compute an infinite series by the end of this term and so we must truncate it at a certain point in the series. The truncated sum of terms represents an approximation to the true exponential, but the approximation may be usable.\nWrite a function that computes the exponential of a number using the truncated series expansion. The function should take two arguments:\nx: the number to be exponentiated\nk: the number of terms to be used in the series expansion beyond the constant 1. The value of k is always \\(\\geq 1\\).\nFor example, if \\(k = 1\\), then the Exp function should return the number \\(1 + x\\). If \\(k = 2\\), then you should return the number \\(1 + x + x^2/2!\\).\nYou can assume that the input value x will always be a single number.\nYou can assume that the value k will always be an integer \\(\\geq 1\\).\nDo not use the exp() function in R.\nThe factorial() function can be used to compute factorials.\n\n\nExp <- function(x, k) {\n        # Add your solution here\n}\n\n\n\nPart 1B: Sample mean and sample standard deviation\nNext, write two functions called sample_mean() and sample_sd() that takes as input a vector of data of length \\(N\\) and calculates the sample average and sample standard deviation for the set of \\(N\\) observations.\n\\[\n\\bar{x} = \\frac{1}{N} \\sum_{i=1}^n x_i\n\\] \\[\ns = \\sqrt{\\frac{1}{N-1} \\sum_{i=1}^N (x_i - \\overline{x})^2}\n\\]\nYou can assume that the input value x will always be a vector of numbers of length \\(N\\).\nDo not use the mean() and sd() functions in R.\n\n\nsample_mean <- function(x) {\n        # Add your solution here\n}\n\nsample_sd <- function(x) {\n        # Add your solution here\n}\n\n\n\nPart 1C: Confidence intervals\nNext, write a function called calculate_CI() that:\nHas two inputs to the calculate_CI() function. First, it should take as input a vector of data of length \\(N\\). Second, the function should also have a conf (\\(=1-\\alpha\\)) argument that allows the confidence interval to be adapted for different \\(\\alpha\\).\nCalculates a confidence interval (CI) (e.g. a 95% CI) for the estimate of the mean in the population. If you are not familiar with confidence intervals, it is an interval that contains the population parameter with probability \\(1-\\alpha\\) taking on this form\n\\[\n\\bar{x} \\pm t_{\\alpha/2, N-1} * s_{\\bar{x}}\n\\]\nwhere \\(t_{\\alpha/2, N-1}\\) is the value needed to generate an area of \\(\\alpha / 2\\) in each tail of the \\(t\\)-distribution with \\(N-1\\) degrees of freedom and \\(s_{\\bar{x}} = \\frac{s}{\\sqrt{N}}\\) is the standard error of the mean. For example, if we pick a 95% confidence interval and \\(N\\)=50, then you can calculate \\(t_{\\alpha/2, N-1}\\) as\n\n\nalpha <- 1 - 0.95\ndegrees_freedom = 50 - 1\nt_score = qt(p=alpha/2, df=degrees_freedom, lower.tail=FALSE)\n\n\n\nReturns a named vector of length 2, where the first value is the lower_bound, the second value is the upper_bound.\n\n\ncalculate_CI <- function(x, conf = 0.95) {\n        # Add your solution here\n}\n\n\n\nNotes\nYou can assume that the input value x will always be a vector of numbers of length \\(N\\).\nDo not use the confint() or other similar functions in R.\nHowever, to help you check if your function output matches the correct answer, assume there exists a vector \\(x\\) of length \\(N\\) and see if the following two code chunks match.\n\n\ncalculate_CI(x, conf = 0.95)\n\n\n\n\n\ndat = data.frame(x=x)\nfit <- lm(x ~ 1, dat)\n\n# Calculate a 95% confidence interval\nconfint(fit, level=0.95)\n\n\n\nPart 2: Wrangling data\nIn this part, we will practice our wrangling skills with the tidyverse that we learned about in module 1.\nData\nThe two datasets for this part of the assignment comes from TidyTuesday. Specifically, we will use the following data from January 2020, which I have provided for you below:\n\n\ntuesdata <- tidytuesdayR::tt_load('2020-01-07')\nrainfall <- tuesdata$rainfall\ntemperature <- tuesdata$temperature\n\n\n\nNote: A useful way to avoid re-downloading data is to write code to check to see if those files already exist using and if() statement:\n\n\nlibrary(here)\nif(!file.exists(here(\"data\",\"tuesdata_rainfall.RDS\"))){\n  tuesdata <- tidytuesdayR::tt_load('2020-01-07')\n  rainfall <- tuesdata$rainfall\n  temperature <- tuesdata$temperature\n  \n  # save the files to RDS objects\n  saveRDS(tuesdata$rainfall, file= here(\"data\",\"tuesdata_rainfall.RDS\"))\n  saveRDS(tuesdata$temperature, file= here(\"data\",\"tuesdata_temperature.RDS\"))\n}\n\n\n\nNote the above code will only run if it cannot find the path to the tuesdata_rainfall.RDS on your computer. Then, we can just read in these files every time we knit the R Markdown, instead of redownloading them every time.\n\n\nrainfall <- readRDS(here(\"data\",\"tuesdata_rainfall.RDS\"))\ntemperature <- readRDS(here(\"data\",\"tuesdata_temperature.RDS\"))\n\n\n\nNow we can look at the data with glimpse()\n\n\nlibrary(tidyverse)\n\nglimpse(rainfall)\n\n\nRows: 179,273\nColumns: 11\n$ station_code <chr> \"009151\", \"009151\", \"009151\", \"009151\", \"009151…\n$ city_name    <chr> \"Perth\", \"Perth\", \"Perth\", \"Perth\", \"Perth\", \"P…\n$ year         <dbl> 1967, 1967, 1967, 1967, 1967, 1967, 1967, 1967,…\n$ month        <chr> \"01\", \"01\", \"01\", \"01\", \"01\", \"01\", \"01\", \"01\",…\n$ day          <chr> \"01\", \"02\", \"03\", \"04\", \"05\", \"06\", \"07\", \"08\",…\n$ rainfall     <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,…\n$ period       <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,…\n$ quality      <chr> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,…\n$ lat          <dbl> -31.96, -31.96, -31.96, -31.96, -31.96, -31.96,…\n$ long         <dbl> 115.79, 115.79, 115.79, 115.79, 115.79, 115.79,…\n$ station_name <chr> \"Subiaco Wastewater Treatment Plant\", \"Subiaco …\n\nglimpse(temperature)\n\n\nRows: 528,278\nColumns: 5\n$ city_name   <chr> \"PERTH\", \"PERTH\", \"PERTH\", \"PERTH\", \"PERTH\", \"PE…\n$ date        <date> 1910-01-01, 1910-01-02, 1910-01-03, 1910-01-04,…\n$ temperature <dbl> 26.7, 27.0, 27.5, 24.0, 24.8, 24.4, 25.3, 28.0, …\n$ temp_type   <chr> \"max\", \"max\", \"max\", \"max\", \"max\", \"max\", \"max\",…\n$ site_name   <chr> \"PERTH AIRPORT\", \"PERTH AIRPORT\", \"PERTH AIRPORT…\n\nIf we look at the TidyTuesday github repo from 2020, we see this dataset contains temperature and rainfall data from Australia.\nHere is a data dictionary for what all the column names mean:\nhttps://github.com/rfordatascience/tidytuesday/blob/master/data/2020/2020-01-07/readme.md#data-dictionary\nTasks\nUsing the rainfall and temperature data, perform the following steps and create a new data frame called df:\nStart with rainfall dataset and drop any rows with NAs.\nCreate a new column titled date that combines the columns year, month, day into one column separated by “-”. (e.g. “2020-01-01”). This column should not be a character, but should be recognized as a date. (Hint check out the ymd() function in lubridate R package). You will also want to add a column that just keeps the year.\nUsing the city_name column, convert the city names (character strings) to all upper case.\nJoin this wrangled rainfall dataset with the temperature dataset such that it includes only observations that are in both data frames. (Hint there are two keys that you will need to join the two datasets together). (Hint: If all has gone well thus far, you should have a dataset with 83,964 rows and 13 columns).\n\n\n# Add your solution here\n\n\n\nNotes\nYou may need to use functions outside these packages to obtain this result, in particular you may find the functions drop_na() from tidyr and str_to_upper() function from stringr useful.\nPart 3: Data visualization\nIn this part, we will practice our ggplot2 plotting skills within the tidyverse that we learned about in module 1 starting with our wrangled df data from Part 2. For full credit in this part (and for all plots that you make), your plots should include:\nAn overall title for the plot and a subtitle summarizing key trends that you found. Also include a caption in the figure.\nThere should be an informative x-axis and y-axis label.\nConsider playing around with the theme() function to make the figure shine, including playing with background colors, font, etc.\nPart 3A: Plotting temperature data over time\nUse the functions in ggplot2 package to make a line plot of the max and min temperature (y-axis) over time (x-axis) for each city in our wrangled data from Part 2. You should only consider years 2014 and onwards. For full credit, your plot should include:\nFor a given city, the min and max temperature should both appear on the plot, but they should be two different colors.\nUse a facet function to facet by city_name to show all cities in one figure.\n\n\n# Add your solution here\n\n\n\nPart 3B: Plotting rainfall over time\nHere we want to explore the distribution of rainfall (log scale) with histograms for a given city (indicated by the city_name column) for a given year (indicated by the year column) so we can make some exploratory plots of the data. Note: you are again using the wrangled data from Part 2.\nThe following code plots the data from one city (city_name == \"PERTH\") in a given year (year == 2000).\n\n\ndf %>% \n  filter(city_name == \"PERTH\", year == 2000) %>% \n  ggplot(aes(log(rainfall))) + \n    geom_histogram()\n\n\n\nWhile this code is useful, it only provides us information on one city in one year. We could cut and paste this code to look at other cities/years, but that can be error prone and just plain messy.\nThe aim here is to design and implement a function that can be re-used to visualize all of the data in this dataset.\nThere are 2 aspects that may vary in the dataset: The city_name and the year. Note that not all combinations of city_name and year have measurements.\nYour function should take as input two arguments city_name and year.\nGiven the input from the user, your function should return a single histogram for that input. Furthermore, the data should be readable on that plot so that it is in fact useful. It should be possible visualize the entire dataset with your function (through repeated calls to your function).\nIf the user enters an input that does not exist in the dataset, your function should catch that and report an error (via the stop() function).\nFor your homework submission\nWrite a short description of how you chose to design your function and why.\nPresent the code for your function in the R markdown document.\nInclude at least one example of output from your function.\n\n\n# Add your solution here\n\n\n\nPart 4: Apply functions and plot\nPart 4A: Tasks\nIn this part, we will apply the functions we wrote in Part 1 to our rainfall data starting with our wrangled df data from Part 2.\nFirst, filter for only years including 2014 and onwards.\nFor a given city and for a given year, calculate the sample mean (using your function sample_mean()), the sample standard deviation (using your function sample_sd()), and a 95% confidence interval for the average rainfall (using your function calculate_CI()). Specifically, you should add two columns in this summarized dataset: a column titled lower_bound and a column titled upper_bound containing the lower and upper bounds for you CI that you calculated (using your function calculate_CI()).\nCall this summarized dataset rain_df.\n\n\n# Add your solution here\n\n\n\nPart 4B: Tasks\nUsing the rain_df, plots the estimates of mean rainfall and the 95% confidence intervals on the same plot. There should be a separate faceted plot for each city. Think about using ggplot() with both geom_point() (and geom_line() to connect the points) for the means and geom_errorbar() for the lower and upper bounds of the confidence interval.\n\n\n# Add your solution here\n\n\n\n\n\n\n",
    "preview": {},
    "last_modified": "2021-09-16T07:52:27-04:00",
    "input_file": {}
  },
  {
    "path": "projects/2021-09-07-project-1/",
    "title": "Project 1",
    "description": "Understanding songs and genres using Spotify audio features",
    "author": [
      {
        "name": "Stephanie Hicks",
        "url": "https://stephaniehicks.com/"
      }
    ],
    "date": "2021-09-07",
    "categories": [
      "project 1",
      "projects"
    ],
    "contents": "\n\nContents\nBackground\nTo submit your project\nInstall tidyverse\nData\n\nPart 1: Explore data\nPart 2: Convert nontidy data into tidy data\nTasks\nNotes\n\nPart 3: Data visualization\nTasks\nNotes\n\nPart 4: Make the worst plot you can!\nTasks\n\nPart 5: Make my plot a better plot!\nTasks\n\n\nBackground\nDue date: Sept 17 at 11:59pm\nTo submit your project\nPlease write up your project using R Markdown and knitr. Compile your document as an HTML file and submit your HTML file to the dropbox on Courseplus. Please show all your code for each of the answers to each part.\nTo get started, watch this video on setting up your R Markdown document.\nInstall tidyverse\nBefore attempting this assignment, you should first install the tidyverse package if you have not already. The tidyverse package is actually a collection of many packages that serves as a convenient way to install many packages without having to do them one by one. This can be done with the install.packages() function.\n\n\ninstall.packages(\"tidyverse\")\n\n\n\nRunning this function will install a host of other packages so it make take a minute or two depending on how fast your computer is. Once you have installed it, you will want to load the package.\n\n\nlibrary(tidyverse)\n\n\n\nFor all of the questions below, you can ignore the missing values in the dataset, so e.g. when taking averages, just remove the missing values before taking the average, if needed.\nData\nThat data for this part of the assignment comes from TidyTuesday, which is a weekly podcast and global community activity brought to you by the R4DS Online Learning Community. The goal of TidyTuesday is to help R learners learn in real-world contexts.\n\n\n\nFigure 1: Icon from TidyTuesday\n\n\n\n[Source: TidyTuesday]\nTo access the data, you need to install the tidytuesdayR R package and use the function tt_load() with the date of ‘2020-01-21’ to load the data.\n\n\ninstall.packages(\"tidytuesdayR\")\n\n\n\n\n\ntuesdata <- tidytuesdayR::tt_load('2020-01-21')\n\n\n\n    Downloading file 1 of 1: `spotify_songs.csv`\n\nspotify_songs <- tuesdata$spotify_songs\nglimpse(spotify_songs)\n\n\nRows: 32,833\nColumns: 23\n$ track_id                 <chr> \"6f807x0ima9a1j3VPbc7VN\", \"0r7CVbZT…\n$ track_name               <chr> \"I Don't Care (with Justin Bieber) …\n$ track_artist             <chr> \"Ed Sheeran\", \"Maroon 5\", \"Zara Lar…\n$ track_popularity         <dbl> 66, 67, 70, 60, 69, 67, 62, 69, 68,…\n$ track_album_id           <chr> \"2oCs0DGTsRO98Gh5ZSl2Cx\", \"63rPSO26…\n$ track_album_name         <chr> \"I Don't Care (with Justin Bieber) …\n$ track_album_release_date <chr> \"2019-06-14\", \"2019-12-13\", \"2019-0…\n$ playlist_name            <chr> \"Pop Remix\", \"Pop Remix\", \"Pop Remi…\n$ playlist_id              <chr> \"37i9dQZF1DXcZDD7cfEKhW\", \"37i9dQZF…\n$ playlist_genre           <chr> \"pop\", \"pop\", \"pop\", \"pop\", \"pop\", …\n$ playlist_subgenre        <chr> \"dance pop\", \"dance pop\", \"dance po…\n$ danceability             <dbl> 0.748, 0.726, 0.675, 0.718, 0.650, …\n$ energy                   <dbl> 0.916, 0.815, 0.931, 0.930, 0.833, …\n$ key                      <dbl> 6, 11, 1, 7, 1, 8, 5, 4, 8, 2, 6, 8…\n$ loudness                 <dbl> -2.634, -4.969, -3.432, -3.778, -4.…\n$ mode                     <dbl> 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1,…\n$ speechiness              <dbl> 0.0583, 0.0373, 0.0742, 0.1020, 0.0…\n$ acousticness             <dbl> 0.10200, 0.07240, 0.07940, 0.02870,…\n$ instrumentalness         <dbl> 0.00e+00, 4.21e-03, 2.33e-05, 9.43e…\n$ liveness                 <dbl> 0.0653, 0.3570, 0.1100, 0.2040, 0.0…\n$ valence                  <dbl> 0.518, 0.693, 0.613, 0.277, 0.725, …\n$ tempo                    <dbl> 122.036, 99.972, 124.008, 121.956, …\n$ duration_ms              <dbl> 194754, 162600, 176616, 169093, 189…\n\nIf we look at the TidyTuesday github repo from 2020, we see this dataset contains songs from Spotify.\nHere is a data dictionary for what all the column names mean:\nhttps://github.com/rfordatascience/tidytuesday/blob/master/data/2020/2020-01-21/readme.md#data-dictionary\nPart 1: Explore data\nIn this part, use functions from dplyr to answer the following questions.\nHow many songs are in each genre?\n\n\n# Add your solution here\n\n\n\n\nWhat is average value of energy and acousticness in the latin genre in this dataset?\n\n\n# Add your solution here\n\n\n\n\nCalculate the average duration of song (in minutes) across all subgenres. Which subgenre has the longest song on average?\n\n\n# Add your solution here\n\n\n\n\nMake two boxplots side-by-side of the danceability of songs stratifying by whether a song has a fast or slow tempo. Define fast tempo as any song that has a tempo above its median value. On average, which songs are more danceable?\nHint: You may find the case_when() function useful in this part, which can be used to map values from one variable to different values in a new variable (when used in a mutate() call).\n\n\n## Generate some random numbers\ndat <- tibble(x = rnorm(100))\nslice(dat, 1:3)\n\n\n# A tibble: 3 × 1\n       x\n   <dbl>\n1 0.288 \n2 0.102 \n3 0.0931\n\n\n## Create a new column that indicates whether the value of 'x' is positive or negative\ndat %>%\n        mutate(is_positive = case_when(\n                x >= 0 ~ \"Yes\",\n                x < 0 ~ \"No\"\n        ))\n\n\n# A tibble: 100 × 2\n         x is_positive\n     <dbl> <chr>      \n 1  0.288  Yes        \n 2  0.102  Yes        \n 3  0.0931 Yes        \n 4  0.742  Yes        \n 5  0.339  Yes        \n 6  0.624  Yes        \n 7 -0.0439 No         \n 8  2.44   Yes        \n 9 -1.34   No         \n10 -1.85   No         \n# … with 90 more rows\n\n\n\n# Add your solution here\n\n\n\n\nPart 2: Convert nontidy data into tidy data\nThe goal of this part of the assignment is to take a dataset that is either messy or simply not tidy and to make them tidy datasets. The objective is to gain some familiarity with the functions in the dplyr, tidyr packages. You may find it helpful to review the section on spreading and gathering data.\nTasks\nThis dataset gives a set of 12 audio features (e.g. acousticness, liveness, speechiness, etc) and descriptors like duration, tempo, key, and mode for a set of 32833 songs (in addition to the artist, album name, album release date, etc).\n\n\nspotify_songs\n\n\n# A tibble: 32,833 × 23\n   track_id  track_name   track_artist track_popularity track_album_id\n   <chr>     <chr>        <chr>                   <dbl> <chr>         \n 1 6f807x0i… I Don't Car… Ed Sheeran                 66 2oCs0DGTsRO98…\n 2 0r7CVbZT… Memories - … Maroon 5                   67 63rPSO264uRjW…\n 3 1z1Hg7Vb… All the Tim… Zara Larsson               70 1HoSmj2eLcsrR…\n 4 75Fpbthr… Call You Mi… The Chainsm…               60 1nqYsOef1yKKu…\n 5 1e8PAfcK… Someone You… Lewis Capal…               69 7m7vv9wlQ4i0L…\n 6 7fvUMiya… Beautiful P… Ed Sheeran                 67 2yiy9cd2QktrN…\n 7 2OAylPUD… Never Reall… Katy Perry                 62 7INHYSeusaFly…\n 8 6b1RNvAc… Post Malone… Sam Feldt                  69 6703SRPsLkS4b…\n 9 7bF6tCO3… Tough Love … Avicii                     68 7CvAfGvq4RlIw…\n10 1IXGILkP… If I Can't … Shawn Mendes               67 4QxzbfSsVryEQ…\n# … with 32,823 more rows, and 18 more variables:\n#   track_album_name <chr>, track_album_release_date <chr>,\n#   playlist_name <chr>, playlist_id <chr>, playlist_genre <chr>,\n#   playlist_subgenre <chr>, danceability <dbl>, energy <dbl>,\n#   key <dbl>, loudness <dbl>, mode <dbl>, speechiness <dbl>,\n#   acousticness <dbl>, instrumentalness <dbl>, liveness <dbl>,\n#   valence <dbl>, tempo <dbl>, duration_ms <dbl>\n\nUse the functions in dplyr, tidyr, and lubridate to perform the following steps to the spotify_songs dataset:\nSelect only unique distinct rows from the dataset based on the track_name and track_artist columns (Hint check out the distinct() function in dplyr).\nAdd a new column called year_released listing just the year that the song was released. (Hint check out the ymd() function in lubridate R package. Also, if you get a warning message with “failed to parse”, check out the truncated argument in the ymd() function.).\nKeep only songs that were released in or after 1980.\nAdd a new column with the duration of the song in minutes\nFor each year_released, calculate the mean of at least 6 of the audio features (e.g. danceability, energy, loudness, etc), or descriptors (e.g. tempo, duration in minutes, etc). (Hint: If all has gone well thus far, you should have a dataset with 41 rows and 7 columns).\nConvert this wide dataset into a long dataset with a new feature and mean_score column\nIt should look something like this:\nyear_released   feature   mean_score\n<dbl>           <chr>       <dbl>\n1980    Danceability    0.5633676       \n1980    Energy  0.7107647       \n1980    Loudness    -8.5211765      \n1980    Valence 0.6333235       \n1980    Tempo   124.1458529     \n1980    Duration    4.2853662       \n1981    Danceability    0.5697258       \n1981    Energy  0.6967581       \n1981    Loudness    -8.8678065      \n1981    Valence 0.6650968   \nNotes\nYou may need to use functions outside these packages to obtain this result.\nNote that the functions in the dplyr and tidyr package expect table-like objects (data frames or tibbles) as their input. You can convert data to these objects using the as_tibble() function in the tibble package.\nDo not worry about the ordering of the rows or columns. Depending on whether you use gather() or pivot_longer(), the order of your output may differ from what is printed above. As long as the result is a tidy data set, that is sufficient.\n\n\n# Add your solution here\n\n\n\n\nPart 3: Data visualization\nIn this part of the project, we will continue to work with our now tidy song dataset from the previous part.\nTasks\nUse the functions in ggplot2 package to make a scatter plot of the six (or more) mean_scores (y-axis) over time (x-axis). For full credit, your plot should include:\nAn overall title for the plot and a subtitle summarizing key trends that you found. Also include a caption in the figure with your name.\nBoth the observed points for the mean_score, but also a smoothed non-linear pattern of the trend\nAll six (or more) plots should be shown in the one figure\nThere should be an informative x-axis and y-axis label\nConsider playing around with the theme() function to make the figure shine, including playing with background colors, font, etc.\nNotes\nYou may need to use functions outside these packages to obtain this result.\nNote that the functions in the dplyr and tidyr package expect table-like objects (data frames or tibbles) as their input. You can convert data to these objects using the as_tibble() function in the tibble package.\nDon’t worry about the ordering of the rows or columns. Depending on whether you use gather() or pivot_longer(), the order of your output may differ from what is printed above. As long as the result is a tidy data set, that is sufficient.\n\n\n# Add your solution here\n\n\n\n\nPart 4: Make the worst plot you can!\nThis sounds a bit crazy I know, but I want this to be FUN! Instead of trying to make a “good” plot, I want you to explore your creative side and make a really awful data visualization in every way. :)\nTasks\nUsing the spotify_songs dataset (and it does not have to be the tidy dataset that we created in Part 2, it can be anything from the original dataset):\nMake the absolute worst plot that you can. You need to customize it in at least 7 ways to make it awful.\nIn your document, write 1 - 2 sentences about each different customization you added (using bullets – i.e. there should be at least 7 bullet points each with 1-2 sentences), and how it could be useful for you when you want to make an awesome data visualization.\n\n\n# Add your solution here\n\n\n\n\nPart 5: Make my plot a better plot!\nThe goal is to take my sad looking plot and make it better! If you’d like an example, here is a tweet I came across of someone who gave a talk about how to zhoosh up your ggplots.\n\n\nspotify_songs %>% \n  ggplot(aes(y=track_popularity, x=playlist_subgenre, fill = playlist_genre)) + \n  geom_violin() +\n  facet_wrap( ~ playlist_genre, scales = \"free_x\")\n\n\n\n\nTasks\nYou need to customize it in at least 7 ways to make it better.\nIn your document, write 1 - 2 sentences about each different customization you added (using bullets – i.e. there should be at least 7 bullet points each with 1-2 sentences), describing how you improved it.\n\n\n# Add your solution here\n\n\n\n\n\n\n\n",
    "preview": "https://github.com/rfordatascience/tidytuesday/raw/master/static/tt_logo.png",
    "last_modified": "2021-09-15T14:54:16-04:00",
    "input_file": {}
  },
  {
    "path": "projects/2021-08-31-project-0/",
    "title": "Project 0 (optional)",
    "description": "Information for Project 0 (entirely optional, but hopefully useful and fun!)",
    "author": [
      {
        "name": "Stephanie Hicks",
        "url": "https://stephaniehicks.com/"
      }
    ],
    "date": "2021-08-31",
    "categories": [
      "project 0",
      "projects"
    ],
    "contents": "\n\nContents\nBackground\nPart 1\nSetting up your computing environment\n\nPart 2\n1. Create a GitHub repo for your website\n2. Build a website using R Markdown\n3. Include a README.md file\n4. Deploy your website\n5. Share your website\n\n\nBackground\nDue date: Sept 9 at 1:29pm\nUsing the tools we learned in the first week (e.g. R, RStudio and Github). Let’s apply them in a small (but also comprehensive) exercise.\nPlease note this project is entirely optional (i.e. it will not be graded), but hopefully it will be helpful to you getting set up for the rest of the course (i.e. set up these tools on your computing environment) and give you an opportunity to introduce yourself to your classmates.\nFor anyone who completes it, you get a free hex sticker! If you aren’t familiar with the hex stickers, check out this link. You can add them to your laptop for some character and swag (or turn them into magnets). I have a ton of different ones from the tidyverse or RLadies Baltimore. You can come pick one up from my office or I can mail it to you if you email me a mailing address after you submit the project.\nFor those of you who are new to GitHub/R/Rmarkdown: this project makes you do a lot of things that you might not be familiar with. I know that this might be time-consuming and also might feel a bit intimidating. It’s partly unavoidable and partly on purpose. You need to learn how to quickly get up to speed with all kinds of new tools that come your way. So practicing it is a good idea. You are welcome to draw on any sources for help that you want (online, classmates, instructor, etc.). I’m confident with a bit of trial and error you’ll get it to work.\nPart 1\nThis part of the project is to ensure that you have successfully set up your computing environment. Please email (use the Subject line: 140.776 Setup) the Course Instructor (Dr. Stephanie Hicks) at shicks19@jhu.edu the following information:\nSetting up your computing environment\nYour name, JHED ID (if applicable).\nThe type of computer/operating system you are using (Windows, Mac, Unix/Linux, other)\nThe version of R that you have installed on your computer. To do this, start up R and run the following in the R console and include the output in your email.\n\n\nprint(R.version.string)\n\n\n\nPrinting the R version stringThe version of RStudio that you have installed on your computer. To do this start up RStudio and in the R console window, run the following and again include the output in your email:\n\n\nprint(RStudio.Version()$version)\n\n\n\nIf you have a GitHub username, please include this in your email. If you do not have a GitHub username, read https://happygitwithr.com, sign up for GitHub, and include your new username in your email to me.\nTo make sure git is installed on your system, use the ‘Terminal’ (e.g. it’s next to the R Console within RStudio) (or whatever you use), run the following and include the output in your email:\nFor example, this is mine:\n\ngit --version\ngit version 2.24.3 (Apple Git-128)\n\nIf you have any trouble with any of the steps above, try to first post on the discussion board on CoursePlus. The TAs and I will be checking it frequently, but other students may also be helpful in their replies. You can also use other resources to get help (Google, R4DS, colleagues/friends/relatives with R/Markdown experience, etc.). Still, try to do as much as possible yourself. We will use all the bits you are learning here repeatedly during this course.\nPart 2\nThis part of the project is to help you introduce yourself (and your interests!) to others in this course. You will create a new GitHub repository and build a small website about yourself.\n1. Create a GitHub repo for your website\nCreate a new GitHub repository titled biostat776-intro-<firstname>-<lastname> (where you replace <firstname> with your first name and <lastname> with your last name) in your own personal GitHub account (e.g. https://github.com/<yourgithubusername>/biostat776-intro-<firstname>-<lastname>).\nFor example, you can find an example that I created for myself at\ngithub repo: https://github.com/stephaniehicks/biostat776-intro-stephanie-hicks\n2. Build a website using R Markdown\nUsing one of the many ways we discussed in class (e.g. a simple R Markdown website, blogdown, distill, etc), create a new project in RStudio with the appropriate files. For example, you might include the following information:\nWrite a short summary introducing yourself. Structure the webpage with headings, subheadings, etc. Talk a bit about yourself, your background, training, research interests. Let me/us know what kind of statistics, programming, data analysis experience you already have. I am also curious to know what you most hope to learn in this course.\nFive fun facts about yourself\nA web page linking to something you think is really cool/interesting/inspiring/etc. You could also describe briefly what it is and why you like it.\nIf you want, feel free to get creative and include other things. You can play with RMarkdown if you wish to, e.g., you can try to include some table or a video, etc.\n3. Include a README.md file\nYour project repository should include a README.md file (if it was not included already).\nEdit the repository README.md file. Typically it will only contain the name of your repository with a # sign in front. The # represents a level 1 heading in Markdown. Change the headline and call it “Introducing myself” (or something like that). Underneath write something like “This website contains a short introduction of Your Name.”\nMake sure the 2 files (README.md and especially index.Rmd / index.html) look the way you want. Make changes until everything works.\n4. Deploy your website\nDepending on how you want to deploy your website, the following may or may not be relevant to you. In general, you want to make sure you have initialized your project to use git (i.e. you can type git init to initialize the repository to use git. Add and commit your changes. Push your changes and deploy your website.\nFollowing steps 2-4, here is my example website:\nwebsite: https://www.stephaniehicks.com/biostat776-intro-stephanie-hicks\n5. Share your website\nGo to the Discussion Board in CoursePlus and write a short post with a link (URL) to your website (and URL to the corresponding GitHub repository) that you created.\nAs you read the introductions from other folks in the class, feel free to comment/reply using Discussion board.\nIn class on Sept 9, I will show as many websites as I can from Courseplus!\n\n\n\n",
    "preview": {},
    "last_modified": "2021-08-26T23:32:27-04:00",
    "input_file": {}
  }
]
